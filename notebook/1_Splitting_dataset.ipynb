{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_Splitting_dataset.ipynb ","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"owovDbKGj5jX"},"source":["# Music Artist PersonalRank Recommender based on social network and tag system\n","\n","\n","\n","**Team 5 : Bo Tong, Honglin Li, Junyi Chen, Li-chen Lin**\n","\n","## TOC\n","* [Section 1: Download and Split data set](#section1)\n","* [Section 2: Tag Clustering](#section2)\n","    * [Section 2.1: Tag preprocessing](#section21)\n","    * [Section 2.2: Tag clustering: BERT](#section22)\n","    * [Section 2.3: Tag clustering: Levenshtein distance](#section23)\n","    * [Section 2.4: Tag clustering: user artist correlation](#section24)\n","    * [Section 2.5: Tag clustering Result](#section25)\n","* [Section 3: PersonalRank-based Recomender](#section3)\n","    * [Section 3.1: User similarity computation](#section31)\n","    * [Section 3.2: Graph Construction](#section32)\n","    * [Section 3.3: PersonalRank implementation: Based on Iteration & Matrix](#section33)\n","    * [Section 3.4: Example](#section34)\n","* [Section 4: User-based CF & Item-based CF Recommenders](#section4)\n","    * [Section 4.1: Calculate similarity matrix for user & item](#section41)\n","    * [Section 4.2: Predict rating based on item-based or user-based methods](#section42)\n","    * [Section 4.3: Recommend artists based on user preference](#section43)\n","* [Section 5: Content-based Recommender](#section5)\n","* [Section 6: Evaluation](#section5)\n","    * [Section 6.1: User-based metrics](#section61)\n","    * [Section 6.2: Item-based metrics](#section62)\n","    * [Section 6.3: Content-based](#section63)\n","    * [Section 6.4: PersonalRank without tags](#section64)\n","    * [Section 6.5: PersonalRank with tags](#section65)"]},{"cell_type":"markdown","metadata":{"id":"JpplQSS1z9ER"},"source":["<a class=\"anchor\" id=\"section1\"></a>\n","\n","## Section 1. Download and Splitting data set\n","- For every user who listen to more than 5 artists, we randomly move 40% of user and artist listening pairs into validation data sets.\n","Remaining data sets are used as train data sets.\n","- In the mean time, we also move the corresponding tag records from user taggedartists table into tag train data sets.\n","- For tags, there are 186479 tagging records, only 73358 tags were tagged from the users who have listened the artists.\n","So we assume: only use the tags tagged by the users who have listened the artists."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zB0sGobBNhnP","executionInfo":{"status":"ok","timestamp":1623662603054,"user_tz":-120,"elapsed":19725,"user":{"displayName":"dami li","photoUrl":"","userId":"13869387854414176006"}},"outputId":"95b75659-5474-4417-ab03-ec54acbc4f62"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/My\\ Drive/WMP"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/My Drive/WMP\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rUISG1Tc72fL"},"source":["import pandas as pd\n","import random\n","import os\n","import zipfile"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dWLPjyYOtERw"},"source":["### Data set download and make directories\n","\n","File Structure:\n","- notebook\n","- data\n"," - dataset\n"," - split\n"," - tags\n"," - interim # put intermiedite output like, translated_tags, similarity_matrix\n"," - external\n"," - result"]},{"cell_type":"code","metadata":{"id":"9T20SYAis_07"},"source":["def make_dir(directory):\n","  if not os.path.exists(directory):\n","    os.makedirs(directory)\n","\n","make_dir('data/split')\n","make_dir('data/tags')\n","make_dir('data/interim')\n","make_dir('data/dataset')\n","make_dir('data/external')\n","make_dir('data/result')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K-g8x4P-1LtY","executionInfo":{"status":"ok","timestamp":1623664382348,"user_tz":-120,"elapsed":713,"user":{"displayName":"dami li","photoUrl":"","userId":"13869387854414176006"}},"outputId":"7e352620-0c4e-4618-ca2a-5bef56607af8"},"source":["# download original data set\n","zip_path = 'data/dataset/hetrec2011-lastfm-2k.zip'\n","!wget --no-check-certificate -P 'data/dataset' 'https://files.grouplens.org/datasets/hetrec2011/hetrec2011-lastfm-2k.zip'\n","\n","zip_file = zipfile.ZipFile(zip_path)\n","for names in zip_file.namelist():\n","    zip_file.extract(names, 'data/dataset')\n","zip_file.close()\n","os.remove(zip_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-06-14 09:53:02--  https://files.grouplens.org/datasets/hetrec2011/hetrec2011-lastfm-2k.zip\n","Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n","Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n","WARNING: cannot verify files.grouplens.org's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n","  Unable to locally verify the issuer's authority.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2589075 (2.5M) [application/zip]\n","Saving to: ‘data/dataset/hetrec2011-lastfm-2k.zip’\n","\n","hetrec2011-lastfm-2 100%[===================>]   2.47M  13.3MB/s    in 0.2s    \n","\n","2021-06-14 09:53:02 (13.3 MB/s) - ‘data/dataset/hetrec2011-lastfm-2k.zip’ saved [2589075/2589075]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4Wbq32nktPEG"},"source":["### Split Data Set"]},{"cell_type":"code","metadata":{"id":"DAkod1z5OD1p"},"source":["# HONGLIN\n","artists_df = pd.read_table('data/dataset/artists.dat')\n","tags_df = pd.read_table('data/dataset/tags.dat', encoding = \"ISO-8859-1\")\n","user_artists_df = pd.read_table('data/dataset/user_artists.dat')  # to be split\n","user_friends_df = pd.read_table('data/dataset/user_friends.dat')\n","user_tag_artists_df = pd.read_table('data/dataset/user_taggedartists.dat')  # to be split\n","\n","artists_df.drop(['pictureURL', 'url'], inplace=True, axis=1)\n","user_tag_artists_df.drop(['day', 'month', 'year'], inplace=True, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dDRHhn8kOQUQ"},"source":["def split_dataset(user_artists_df, user_tag_artists_df, train_prefix='train', test_prefix='test'):\n","  df = user_artists_df\n","  if 'name' not in user_artists_df.columns:\n","    df = pd.merge(artists_df, user_artists_df, how=\"inner\", left_on='id', right_on='artistID').drop(['id'], axis = 1)  # add name\n","  print('User_Artist Shape: ', df.shape)\n","\n","  # Check how many artists are listened by each user\n","  user_artists_count = user_artists_df.groupby(['userID']).agg({'artistID' : 'count'}).rename(columns={'artistID': 'artistCount'})\n","\n","  # 1.Splitting train and validation/test data on user_artists\n","  # 1.1 test/validation set\n","  user_candidate_val = user_artists_count[user_artists_count.artistCount>5]\n","  test_user_artists = df.merge(user_candidate_val, how='inner', on='userID').drop(['artistCount'], axis = 1)\n","  test_user_artists = test_user_artists.sample(frac=0.4, random_state=41)\n","\n","  # 1.2 train set\n","  train_user_artists = pd.concat([df,test_user_artists]).drop_duplicates(keep=False)\n","  print('Shape of user_artists train set: ', train_user_artists.shape)\n","  print('Coverage rate of User in train set:', len(train_user_artists['userID'].unique())/len(df['userID'].unique()))\n","  print('Coverage rate of artist in train set: ', len(train_user_artists['artistID'].unique())/len(df['artistID'].unique()))\n","\n","  # 2.splitting on user_taggedartists    for tags, we just need train set, do not need test set\n","  train_user_taggedartists = user_tag_artists_df.merge(train_user_artists.drop(columns = ['name','weight']), how='inner', on=['userID', 'artistID'])\n","  #train_user_taggedartists = train_user_taggedartists.drop(columns = ['name','weight'])\n","  print('Shape of train set of user_artist_tag: ', train_user_taggedartists.shape)\n","\n","  # save to local\n","  if not os.path.exists('data/split'):\n","    os.makedirs('data/split')\n","\n","  test_user_artists.to_csv(f'data/split/{test_prefix}_user_artists.csv', index=False)\n","  train_user_artists.to_csv(f'data/split/{train_prefix}_user_artists.csv', index=False)\n","  train_user_taggedartists.to_csv(f'data/split/{train_prefix}_user_taggedartists.csv', index=False)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ilw-8VBeWpg-","executionInfo":{"status":"ok","timestamp":1623410743392,"user_tz":-120,"elapsed":873,"user":{"displayName":"dami li","photoUrl":"","userId":"13869387854414176006"}},"outputId":"e340fdc8-a2f0-40ea-fba8-2b62edf3116a"},"source":["# split dataset to train set and test set\n","split_dataset(user_artists_df, user_tag_artists_df)\n","\n","# split train set to train set and validation set\n","train_user_artists = pd.read_csv('data/split/train_user_artists.csv')\n","train_user_taggedartists = pd.read_csv('data/split/train_user_taggedartists.csv')\n","split_dataset(train_user_artists, train_user_taggedartists, train_prefix='train_tune', test_prefix='val')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["User_Artist Shape:  (92834, 4)\n","Shape of user_artists train set:  (55716, 4)\n","Coverage rate of User in train set: 1.0\n","Coverage rate of artist in train set:  0.7296960072595281\n","Shape of train set of user_artist_tag:  (44009, 3)\n","User_Artist Shape:  (55716, 4)\n","Shape of user_artists train set:  (33454, 4)\n","Coverage rate of User in train set: 1.0\n","Coverage rate of artist in train set:  0.7264106948546557\n","Shape of train set of user_artist_tag:  (26188, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tuEepq4jgqPK"},"source":["# coverage after spliting\n","artist_count = len(user_artists_df['artistID'].unique())\n","user_count = len(user_artists_df['userID'].unique())\n","tag_count = len(user_tag_artists_df['tagID'].unique())\n","\n","train_user = pd.read_csv('data/split/train_user_artists.csv')\n","train_tag = pd.read_csv('data/split/train_user_taggedartists.csv')\n","\n","train_tune_user = pd.read_csv('data/split/train_tune_user_artists.csv')\n","train_tune_tag = pd.read_csv('data/split/train_tune_user_taggedartists.csv')\n","\n","val_user = pd.read_csv('data/split/val_user_artists.csv')\n","\n","test_user = pd.read_csv('data/split/test_user_artists.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y4SjLDvDjxpE","executionInfo":{"status":"ok","timestamp":1623625392046,"user_tz":-120,"elapsed":355,"user":{"displayName":"dami li","photoUrl":"","userId":"13869387854414176006"}},"outputId":"e8e803c9-24dc-4ca8-a2e4-d43f6ac3eacd"},"source":["train_user_count = len(train_user.userID.unique())\n","train_artist_count = len(train_user.artistID.unique())\n","train_tag_count = len(train_tag.tagID.unique())\n","\n","train_tune_user_count = len(train_tune_user.userID.unique())\n","train_tune_artist_count = len(train_tune_user.artistID.unique())\n","train_tune_tag_count = len(train_tune_tag.tagID.unique())\n","\n","val_user_count = len(val_user.userID.unique())\n","val_artist_count = len(val_user.artistID.unique())\n","\n","test_user_count = len(test_user.userID.unique())\n","test_artist_count = len(test_user.artistID.unique())\n","\n","print(f'user ratio in train set: {train_user_count / user_count}')\n","print(f'user ratio in train tune set: {train_tune_user_count / user_count}')\n","print(f'user ratio in val set: {val_user_count / user_count}')\n","print(f'user ratio in test set: {test_user_count / user_count}')\n","\n","print(f'artist ratio in train set: {train_artist_count / artist_count}')\n","print(f'artist ratio in train tune set: {train_tune_artist_count / artist_count}')\n","print(f'artist ratio in val set: {val_artist_count / artist_count}')\n","print(f'artist ratio in test set: {test_artist_count / artist_count}')\n","\n","print(f'tag ratio in train set: {train_tag_count / tag_count}')\n","print(f'tag ratio in train tune set: {train_tune_tag_count / tag_count}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["user ratio in train set: 1.0\n","user ratio in train tune set: 1.0\n","user ratio in val set: 0.9889006342494715\n","user ratio in test set: 0.9915433403805497\n","artist ratio in train set: 0.7296960072595281\n","artist ratio in train tune set: 0.5300589836660617\n","artist ratio in val set: 0.40625\n","artist ratio in test set: 0.5688520871143375\n","tag ratio in train set: 0.6080623653708073\n","tag ratio in train tune set: 0.4573802441276028\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pUIdha77m2V7"},"source":[""],"execution_count":null,"outputs":[]}]}