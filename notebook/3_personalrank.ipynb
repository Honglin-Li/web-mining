{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_personalrank.ipynb（副本）","provenance":[{"file_id":"15GXGzPi4wc0XvLEsZfe7LP0ryNkxkygG","timestamp":1621721583251}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0qXJFYMwf4li"},"source":["# **PersonalRank Recommender**"]},{"cell_type":"markdown","metadata":{"id":"LXH4J0T6gb6S"},"source":["## **Import Data**"]},{"cell_type":"code","metadata":{"id":"Rf7A2jkof3PF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623673802332,"user_tz":-480,"elapsed":371,"user":{"displayName":"Bo Tong","photoUrl":"","userId":"12866079862663104872"}},"outputId":"70c5876e-5a6d-45a1-cc20-9eb3cea36e71"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/My\\ Drive/Web mining project"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/.shortcut-targets-by-id/1o8pv34povS0R5_x0ABuISxxGG3LxQ3ET/Web mining project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f0rCXlDYMhI0","executionInfo":{"status":"ok","timestamp":1623673803609,"user_tz":-480,"elapsed":213,"user":{"displayName":"Bo Tong","photoUrl":"","userId":"12866079862663104872"}}},"source":["import pandas as pd\n","import operator\n","import pickle\n","from scipy.sparse.linalg import gmres\n","from scipy.sparse import csr_matrix\n","import numpy as np\n","import math"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"HPV3yxgg9Q4P","executionInfo":{"status":"ok","timestamp":1623674262914,"user_tz":-480,"elapsed":321,"user":{"displayName":"Bo Tong","photoUrl":"","userId":"12866079862663104872"}}},"source":["user_friends_df = pd.read_table('data/dataset/user_friends.dat')\n","df_train = pd.read_csv('data/split/train_user_artists.csv')\n","df_train_tune = pd.read_csv('data/split/train_tune_user_artists.csv')\n","df_train_tune = df_train_tune[['artistID', 'userID', 'weight']]\n","df_val = pd.read_csv('data/split/val_user_artists.csv')\n","df_test = pd.read_csv('data/split/test_user_artists.csv')\n","tag_train = pd.read_csv('data/tags/correlation_tags_train_0.4_average.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E4qaeZLYg328"},"source":["## **User Similarity Computation**"]},{"cell_type":"code","metadata":{"id":"_HdlBM4fbY7U","executionInfo":{"status":"ok","timestamp":1623673994903,"user_tz":-480,"elapsed":1837,"user":{"displayName":"Bo Tong","photoUrl":"","userId":"12866079862663104872"}}},"source":["#Function to calculate the similarity between users\n","\n","#Represent each user with tfidf value\n","def user_tfidf(user_friends_df,  df_train):\n","  tf = dict()\n","  idf = dict()\n","  tfidf = dict()\n","  count = dict()\n","  artist_con = dict()\n","  user_list = []\n","  artist_list = []\n","  for i in range(len(df_train)):\n","    user,artist,weight=str(df_train['userID'][i]),\"artist_\"+str(df_train['artistID'][i]),df_train['weight'][i]\n","    if user not in user_list:\n","      user_list.append(user)\n","    if artist not in artist_list:\n","      artist_list.append(artist)\n","      artist_con[artist] = 0\n","    if user not in count:\n","      count[user] = dict()\n","    count[user][artist] = weight\n","    artist_con[artist] += 1\n","  for user in user_list:\n","    tf[user] = dict()\n","    idf[user] = dict()\n","    tfidf[user] = dict()\n","    for artist in count[user]:\n","      tf[user][artist] = count[user][artist]  / sum(count[user].values())\n","      idf[user][artist] = math.log(len(artist_list) / artist_con[artist])\n","      tfidf[user][artist] = tf[user][artist] * idf[user][artist]\n","  return tfidf\n","\n","#Calculate cosine similarity based on tfidf values\n","def user_cosine_similarity(user1, user2, tfidf):\n","  nume = 0\n","  sum_user1 = 0\n","  sum_user2 = 0\n","  for artist in tfidf[user1].keys() & tfidf[user2].keys():\n","    nume += tfidf[user1][artist] * tfidf[user2][artist]\n","  for value in tfidf[user1].values():\n","    sum_user1 += pow(value,2)\n","  for value in tfidf[user2].values():\n","    sum_user2 += pow(value,2)\n","  similarity = nume / (pow(sum_user1, 0.5) * pow(sum_user2, 0.5))\n","  return similarity"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"vfUYhdXYkj3_","executionInfo":{"status":"ok","timestamp":1623674160411,"user_tz":-480,"elapsed":156950,"user":{"displayName":"Bo Tong","photoUrl":"","userId":"12866079862663104872"}}},"source":["#calculate similarity and save it as similarity.pickle\n","tfidf = user_tfidf(user_friends_df,  df_train)\n","user_list = []\n","similarity = {}\n","for i in range(len(df_train)):\n","  user,artist,weight=str(df_train['userID'][i]),\"artist_\"+str(df_train['artistID'][i]),df_train['weight'][i]\n","  if user not in user_list:\n","    user_list.append(user)\n","for user in user_list:\n","  similarity[user] = dict()\n","  for user1 in user_list:\n","    similarity[user][user1] = user_cosine_similarity(user, user1, tfidf)\n","\n","#the similarity matrix have been saved in data/interim/similarity.pickle\n","with open('data/interim/similarity.pickle', 'wb') as f:\n","  f.write(pickle.dumps(similarity))"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MYMofNDshlvm"},"source":["## **Graph Construction**"]},{"cell_type":"markdown","metadata":{"id":"KGEP4fYyi09l"},"source":["### Without tag"]},{"cell_type":"code","metadata":{"id":"yUnwJ6aWi8uP","executionInfo":{"status":"ok","timestamp":1623675984437,"user_tz":-480,"elapsed":2922,"user":{"displayName":"Bo Tong","photoUrl":"","userId":"12866079862663104872"}}},"source":["similarity = pickle.loads(open('data/interim/similarity.pickle', \"rb\").read())\n","k_friend = 0.3\n","k_artist = 1\n","\n","#build random walk graph\n","def buildGrapha_without_tag(df_train, user_friends_df, k_friend, k_artist, similarity):\n","  graph = dict()\n","  weights = dict()\n","  friends = dict()\n","  user_list = []\n","  tags = dict()\n","  tag_list = []\n","  \n","  #user_artist data\n","  for i in range(len(df_train)):\n","    user,artist,weight=str(df_train['userID'][i]),\"artist_\"+str(df_train['artistID'][i]),df_train['weight'][i]\n","    if user not in user_list:\n","      user_list.append(user)\n","    if user not in graph:\n","      graph[user] = dict()\n","      weights[user] = weight\n","    else:\n","      weights[user] += weight\n","    graph[user][artist] = weight\n","    if artist not in graph:\n","      graph[artist]=dict()\n","      weights[artist] = weight\n","    else:\n","      weights[artist] += weight\n","    graph[artist][user] = weight\n","  \n","  #transform the weight of edges between user and artist\n","  for users in user_list:\n","    for artists in graph[users]:\n","      # print(users + artist)\n","      tmp = graph[users][artists]\n","      graph[users][artists] = k_artist * tmp / (weights[users] * 1.0)\n","      graph[artists][users] = k_artist * tmp / (weights[artists] * 1.0)\n","\n","  #user_friend data\n","  for i in range(len(user_friends_df)):\n","    user, friend = str(user_friends_df['userID'][i]), str(user_friends_df['friendID'][i])\n","    if user not in graph:\n","      graph[user] = dict()\n","    if user not in friends:\n","      friends[user] = []\n","    graph[user][friend] = 0.5 + 0.5 * similarity[user][friend]\n","    friends[user].append(friend)\n","\n","  #transform the weight of edges between users and friends\n","  for user,friend_list in friends.items():\n","    for friend in friend_list:\n","      graph[user][friend] = k_friend * graph[user][friend] / (1.0 * len(friend_list))\n","\n","\n","  for point, point_dic in graph.items():\n","    weights_sum = sum(graph[point].values())   \n","    for next_point in graph[point]:\n","      if weights_sum != 0:\n","        graph[point][next_point] = graph[point][next_point] / weights_sum\n","  \n","  return graph"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pSkyV7ytknoy"},"source":["### With Tag"]},{"cell_type":"code","metadata":{"id":"WMh5MQJdhjzb","executionInfo":{"status":"ok","timestamp":1623674209189,"user_tz":-480,"elapsed":2119,"user":{"displayName":"Bo Tong","photoUrl":"","userId":"12866079862663104872"}}},"source":["similarity = pickle.loads(open('data/interim/similarity.pickle', \"rb\").read())\n","k_friend = 0.3\n","k_tag = 0.1\n","k_artist = 1\n","\n","#build random walk graph\n","def buildGrapha_with_tag(df_train, tag_train, user_friends_df, k_friend, k_tag, k_artist, similarity):\n","  graph = dict()\n","  weights = dict()\n","  friends = dict()\n","  user_list = []\n","  tags = dict()\n","  tag_list = []\n","  \n","  #user_artist data\n","  for i in range(len(df_train)):\n","    user,artist,weight=str(df_train['userID'][i]),\"artist_\"+str(df_train['artistID'][i]),df_train['weight'][i]\n","    if user not in user_list:\n","      user_list.append(user)\n","    if user not in graph:\n","      graph[user] = dict()\n","      weights[user] = weight\n","    else:\n","      weights[user] += weight\n","    graph[user][artist] = weight\n","    if artist not in graph:\n","      graph[artist]=dict()\n","      weights[artist] = weight\n","    else:\n","      weights[artist] += weight\n","    graph[artist][user] = weight\n","  \n","  #transform the weight of edges between user and artist\n","  for users in user_list:\n","    for artists in graph[users]:\n","      # print(users + artist)\n","      tmp = graph[users][artists]\n","      graph[users][artists] = k_artist * tmp / (weights[users] * 1.0)\n","      graph[artists][users] = k_artist * tmp / (weights[artists] * 1.0)\n","\n","  #user_friend data\n","  for i in range(len(user_friends_df)):\n","    user, friend = str(user_friends_df['userID'][i]), str(user_friends_df['friendID'][i])\n","    if user not in graph:\n","      graph[user] = dict()\n","    if user not in friends:\n","      friends[user] = []\n","    graph[user][friend] = 0.5 + 0.5 * similarity[user][friend]\n","    friends[user].append(friend)\n","\n","  #transform the weight of edges between users and friends\n","  for user,friend_list in friends.items():\n","    for friend in friend_list:\n","      graph[user][friend] = k_friend * graph[user][friend] / (1.0 * len(friend_list))\n","\n","\n","  #user_tag_artist data\n","\n","  for i in range(len(tag_train)):\n","    user, artist,\ttag = str(tag_train['userID'][i]),\"artist_\"+str(tag_train['artistID'][i]),\"tag_\" + str(tag_train['cluster'][i])\n","    if tag not in tag_list:\n","      tag_list.append(tag)\n","    if user not in graph:\n","      graph[user] = dict()\n","    if user not in tags:\n","      tags[user] = []\n","    if tag not in graph:\n","      graph[tag] = dict()\n","    if tag not in tags:\n","      tags[tag] = []\n","    if artist not in graph:\n","      graph[artist] = dict()\n","    if artist not in tags:\n","      tags[artist] = []\n","    if tag not in graph[user]:\n","      graph[user][tag] = 0\n","      graph[tag][user] = 0\n","    if artist not in graph[tag]:\n","      graph[tag][artist] = 0\n","      graph[artist][tag] = 0\n","    tags[user].append(tag)\n","    tags[tag].append(user)\n","    tags[tag].append(artist)\n","    tags[artist].append(tag)\n","    graph[user][tag] += 1\n","    graph[tag][user] += 1\n","    graph[tag][artist] += 1\n","    graph[artist][tag] += 1\n","  \n","  #transform the weight of edges between users, tags and artists\n","  for tag in tag_list:\n","    for links in graph[tag]:\n","      graph[links][tag] = k_tag * graph[links][tag] / (1.0 * len(tags[links]))\n","      graph[tag][links] = k_tag * graph[tag][links] / (1.0 * len(tags[tag]))\n","\n","  for point, point_dic in graph.items():\n","    weights_sum = sum(graph[point].values())   \n","    for next_point in graph[point]:\n","      if weights_sum != 0:\n","        graph[point][next_point] = graph[point][next_point] / weights_sum\n","  \n","  return graph"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BvOCLHY9g_Gs"},"source":["## **Implementation**"]},{"cell_type":"markdown","metadata":{"id":"FPWv3lXEiB96"},"source":["### Based on Iteration"]},{"cell_type":"code","metadata":{"id":"Llo0GWIFUDSs","executionInfo":{"status":"ok","timestamp":1623674226360,"user_tz":-480,"elapsed":217,"user":{"displayName":"Bo Tong","photoUrl":"","userId":"12866079862663104872"}}},"source":["#Personal_rank algorithm based on iteration \n","def personal_rank(graph,root,alpha,iter_step,recom_num=10):\n","    rank={}\n","    rank={point:0 for point in graph}  \n","    rank[root]=1 \n","    result={}\n","    for i in range(iter_step):\n","        tmp_rank={}   \n","        tmp_rank={point:0 for point in graph}\n","        for out_point,out_dict in graph.items(): \n","            for inner_point,value in graph[out_point].items():\n","                tmp_rank[inner_point]+=alpha*rank[out_point]*graph[out_point][inner_point]\n","                if inner_point==root:\n","                    tmp_rank[inner_point]+=1-alpha\n","        if tmp_rank==rank:\n","            print(\"converged\")\n","            break  \n","        rank=tmp_rank\n","    right_num=0  \n","    for instance in sorted(rank.items(),key=operator.itemgetter(1),reverse=True):\n","        point,pr_score=instance[0],instance[1]\n","        if point.split('_')[0] != 'artist':\n","            continue   \n","        if point in graph[root]:\n","            continue \n","        result[point]=pr_score\n","        right_num+=1\n","        if right_num>=recom_num:   \n","            break\n","    return result    "],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z6RDXJdqCWn6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623674297948,"user_tz":-480,"elapsed":26329,"user":{"displayName":"Bo Tong","photoUrl":"","userId":"12866079862663104872"}},"outputId":"d3543d3b-53a6-40b1-83e3-b41e29e99c16"},"source":["#Example: Caluculate the recommendation result for user 8\n","graph = buildGrapha(df_train, tag_train, user_friends_df, k_friend, k_tag, k_artist, similarity)\n","alpha=0.6\n","user='8'\n","iter_num=100\n","recom_resul=personal_rank(graph,user,alpha,iter_num,20)\n","print(recom_resul)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["converged\n","{'artist_289': 0.26579554098096797, 'artist_67': 0.09110335127858468, 'artist_701': 0.0711861437473364, 'artist_461': 0.06527547715682365, 'artist_55': 0.06396432918925081, 'artist_466': 0.0515463385993612, 'artist_257': 0.04747780413976701, 'artist_333': 0.044607007119820845, 'artist_498': 0.041091796454603736, 'artist_679': 0.040216629399768646, 'artist_294': 0.03382895681756284, 'artist_157': 0.031882693071810776, 'artist_302': 0.02843711671329293, 'artist_325': 0.02792381429026603, 'artist_306': 0.02446216352595119, 'artist_227': 0.02105021385303625, 'artist_299': 0.020985774285988704, 'artist_318': 0.02048224669327192, 'artist_72': 0.019176131523366592, 'artist_906': 0.019137861768216094}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LzrKsAnwhQi0"},"source":["### Based on Matrix"]},{"cell_type":"code","metadata":{"id":"Ki0QFqfmMo-H","executionInfo":{"status":"ok","timestamp":1623674330151,"user_tz":-480,"elapsed":215,"user":{"displayName":"Bo Tong","photoUrl":"","userId":"12866079862663104872"}}},"source":["#Another efficient method to implement personal_rank algorithm\n","\n","#Transform dictionary graph into matrix\n","def get_matrix_from_graph(graph):\n","  M=[]\n","  for point in graph.keys():\n","      row = []\n","      for next_point in graph.keys():\n","          if next_point in graph[point]:\n","              weight=graph[point][next_point]\n","              row.append(weight)\n","          else:\n","              row.append(0)\n","      M.append(row)\n","  return np.matrix(M)\n","\n","#Transform matrix into csr matrix\n","def get_csr_matrix(M, alpha):\n","  n = M.shape[0]\n","  M1 = np.eye(n) - alpha * M.T\n","  data = []\n","  row_list = []\n","  col_list = []\n","  for row in range(n):\n","    for col in range(n):\n","      if (M1[row, col] != 0):\n","        data.append(M1[row, col])\n","        row_list.append(row)\n","        col_list.append(col)\n","  M = csr_matrix((data, (row_list, col_list)), shape=(n, n))\n","  return M\n","\n","#Do personal_rank algorithm based on csr matrix\n","def personal_rank_based_on_matrix(graph, csr_matrix, user, alpha, recom_num=10):\n","  items=[]\n","  vertex=list(graph.keys())\n","  index=list(graph.keys()).index(user)\n","  n = csr_matrix.shape[0]\n","  zeros=np.zeros((n,1))\n","  zeros[index][0]=1\n","  r0=np.matrix(zeros)\n","  b = (1 - alpha) * r0\n","  res = gmres(csr_matrix, b, tol=1e-08)[0]\n","  tmp = {}\n","  result = {}\n","  for index in range(len(res)):\n","    point=vertex[index]\n","    tmp[point]=res[index]\n","  right_num=0  \n","  for instance in sorted(tmp.items(),key=operator.itemgetter(1),reverse=True):\n","      point,pr_score=instance[0],instance[1]\n","      if point.split('_')[0] != 'artist':\n","          continue   \n","      if point in graph[user]:\n","          continue \n","      result[point]=pr_score\n","      right_num+=1\n","      if right_num>=recom_num:   \n","          break\n","  return result"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AdJUyksDjneX"},"source":["## Example"]},{"cell_type":"code","metadata":{"id":"i_ju6fu06rex","executionInfo":{"status":"ok","timestamp":1623676418515,"user_tz":-480,"elapsed":428490,"user":{"displayName":"Bo Tong","photoUrl":"","userId":"12866079862663104872"}}},"source":["#Define the possibility that the walker continues walking as 0.8\n","alpha = 0.6\n","\n","#construct graph and transform it into sparse matrix\n","graph = buildGrapha_without_tag(df_train,  user_friends_df, k_friend, k_artist, similarity)\n","M = get_matrix_from_graph(graph)\n","csr_m = get_csr_matrix(M, alpha)\n","\n","#get the user list to recommend\n","user_list = df_val['userID'].unique()\n","\n","rc = {}\n","rc['userID'] = []\n","rc['recom_artist'] = []\n","rc['confidence'] = []\n","for user in user_list:\n","  str_user = str(user)\n","  result = personal_rank_based_on_matrix(graph, csr_m, str_user, alpha, recom_num=10)\n","  for artist,confidence in result.items():\n","    rc['userID'].append(user)\n","    artist = int(artist.split('_')[1])\n","    rc['recom_artist'].append(artist)\n","    rc['confidence'].append(confidence)\n","df = pd.DataFrame(rc)\n","df.to_csv('data/result/personalrank_without_tag.csv')"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p8DJNj3ujww0"},"source":["## Pickle Matrix"]},{"cell_type":"code","metadata":{"id":"TwElDMagSS7f","executionInfo":{"status":"ok","timestamp":1623676662465,"user_tz":-480,"elapsed":216,"user":{"displayName":"Bo Tong","photoUrl":"","userId":"12866079862663104872"}}},"source":["#The matrix and csr matrix has been saved in data/interim/matrix.pickle and data/interim/csr_matrix.pickle\n","with open('data/interim/matrix_without_tag.pickle', 'wb') as f:\n","  f.write(pickle.dumps(M))\n","with open('data/interim/csr_matrix_without_tag', 'wb') as f:\n","  f.write(pickle.dumps(csr_m))"],"execution_count":38,"outputs":[]}]}